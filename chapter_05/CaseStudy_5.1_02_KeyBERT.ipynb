{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "380f2db9-5046-4c29-86a2-fe2871cd4352",
   "metadata": {},
   "source": [
    "# Case Study 5.1 - 02 KeyBERT\n",
    "\n",
    "In this script we are using a library called KeyBERT to create semnatically informed keyword representation of the data.\n",
    "\n",
    "KeyBERT works by identifying words or phrases in the text block that are closest in meaning the the meaning of the complete text.\n",
    "\n",
    "The original scripts for the content of this Notebook can be found here:\n",
    "* [CaseStudy_5.1_02-01.py](CaseStudy_5.1_02-01.py)\n",
    "* [CaseStudy_5.1_02-02.py](CaseStudy_5.1_02-02.py)\n",
    "\n",
    "<span style=\"color: #FF0000;\">Errata:</span> The listing presented in the book for the manipulation and display of the keywords contained several typos. These are corrected below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c7fe7d4-42b0-4f79-be3a-031aa8f0dedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyBERT\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa84966-0b9a-45bb-bd40-c2ed0ad9f109",
   "metadata": {},
   "source": [
    "We use a different version of tqdm designed for Notebooks.\n",
    "This line is different from the content of the book and the original script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7c095f7-81f1-47b8-a33b-0e72198dd79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34234593-0cc5-407d-8493-957e6431e156",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/complete_with_features.csv\")\n",
    "test = df[df[\"RANDOM\"]>=0.95]\n",
    "\n",
    "text_list = test['text'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2564881a-c636-4ab9-b6a4-bcca4a7de95f",
   "metadata": {},
   "source": [
    "## Part 01 - Key Word Extraction\n",
    "\n",
    "We start by just extracting keywords from across all text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e67b9cbb-5f74-438a-85cb-14cd5abd9a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name bert-base-uncased. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "kw_model = KeyBERT(model=model_name)\n",
    "\n",
    "def extract_keywords(texts, top_n=3):\n",
    "    all_keywords = []\n",
    "    for text in tqdm(texts, desc=\"Extracting keywords\"):\n",
    "        keywords = kw_model.extract_keywords(text, top_n=top_n, stop_words='english')\n",
    "        all_keywords.extend([kw[0] for kw in keywords])\n",
    "    return Counter(all_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bed7955-ed36-436d-b09f-801883d30ddc",
   "metadata": {},
   "source": [
    "**Note:** Due to a Hardware/Library Compatibility (Specific to M4 Macs) we include Numpy specific warning suppressions.\n",
    "\n",
    "If you are using Windows or Linux, or an Intel Mac then you will not need to encapsulate the `extract_keywords` function call inside the `with np.errstate` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea5d71a9-f95b-477d-93f8-69d96f7c556c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "824e471e2701489085772dc5987456a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting keywords:   0%|          | 0/3244 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with np.errstate(divide='ignore', invalid='ignore', over='ignore'):\n",
    "    keywds = extract_keywords(text_list, top_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "522e47ae-8fce-4fa7-85de-686d37c4ad86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|      | keyword         |   count |\n",
      "|-----:|:----------------|--------:|\n",
      "|   25 | feel            |     189 |\n",
      "|  715 | extracurricular |     100 |\n",
      "| 1337 | student_name    |      86 |\n",
      "|    8 | stressful       |      84 |\n",
      "|  392 | hey             |      77 |\n"
     ]
    }
   ],
   "source": [
    "df_keywords = pd.DataFrame({\n",
    "    \"keywords\": pd.Series(keywds)\n",
    "}).fillna(0).astype(int).reset_index()\n",
    "\n",
    "df_keywords.columns=['keyword','count']\n",
    "df_keywords = df_keywords.sort_values(by='count', ascending=False)\n",
    "\n",
    "keywords = df_keywords[df_keywords['count']>=30]\n",
    "\n",
    "print(keywords.head(5).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aad8f7f-f556-421a-9e83-a8aa33be3b27",
   "metadata": {},
   "source": [
    "## Part 02 - Key Phrase Extraction\n",
    "\n",
    "We modify our extraction function slightly to extract key phrases rather than words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "226d6d6e-85fb-44f2-b047-1e3a94273d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords2(texts, top_n=3):\n",
    "    all_keywords = []\n",
    "    for text in tqdm(texts, desc=\"Extracting keywords\"):\n",
    "        keywords = kw_model.extract_keywords(text, top_n=top_n, keyphrase_ngram_range=(2, 3), stop_words='english')\n",
    "        all_keywords.extend([kw[0] for kw in keywords])\n",
    "    return Counter(all_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10043d1f-f312-4eb4-871f-743436de74d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54dcdebedc144e787dcb957199e504f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting keywords:   0%|          | 0/3244 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with np.errstate(divide='ignore', invalid='ignore', over='ignore'):\n",
    "    keywds2 = extract_keywords2(text_list, top_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a50063ae-0e8c-426b-aac9-7ea7821ac09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|      | keyphrase                    |   count |\n",
      "|-----:|:-----------------------------|--------:|\n",
      "| 3825 | make informed decisions      |      31 |\n",
      "| 5423 | reduce traffic congestion    |      30 |\n",
      "| 5959 | support abolishing electoral |      22 |\n",
      "| 5738 | abolishing electoral college |      21 |\n",
      "| 3612 | making decisions             |      16 |\n"
     ]
    }
   ],
   "source": [
    "df_keywords2 = pd.DataFrame({\n",
    "    \"keywords\": pd.Series(keywds2)\n",
    "}).fillna(0).astype(int).reset_index()\n",
    "\n",
    "df_keywords2.columns=['keyphrase','count']\n",
    "keywords2 = df_keywords2[df_keywords2['count']>=10]\n",
    "keywords2 = keywords2.sort_values(by='count', ascending=False)\n",
    "\n",
    "print(keywords2.head(5).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be41318-8bcd-44cc-8422-786cff68553a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
